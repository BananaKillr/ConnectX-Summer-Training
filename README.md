# ConnectX-Summer-Training
# ğŸ“š LangGraph + RAG Chatbot

This project combines:
- **RAG (Retrieval-Augmented Generation)** for answering questions from uploaded documents.
- **LangGraph** for controlled conversation flows and message management.

It provides:
1. **Backend** (FastAPI) with endpoints for:
   - Uploading documents
   - Querying via RAG
   - Querying via LangGraph
2. **Frontend** (Streamlit) chat interface.

---

```
## âš™ï¸ 1. Environment Setup
```

### Step 1 â€” Create Python Environment  
Use **Python 3.12**:
```bash
# Create a virtual environment
python3.12 -m venv venv

# Activate it
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
```

### Step 2 â€” Install Dependencies  

Dependencies are listed in:
```
src/requirements.txt
```

Install them:
```bash
pip install -r src/requirements.txt
```

---

```
## ğŸ”‘ 2. Environment Variables
```

The project uses a `.env` file for API keys and configuration.

### Step 1 â€” Create `.env`  
Copy the example file:
```bash
cp .env.example .env
```

### Step 2 â€” Fill in values  

All environment variables are loaded in:
```
src/Config/config.py
```
You must update `.env` with:
```
GOOGLE_API_KEY=your_google_api_key_here
GEMINI_MODEL_NAME=
EMBEDDING_MODEL_NAME=
Qdrant_db_path=./datastore
Qdrant_distance_method=dot
TEXT_EMBEDDING_MODEL_SIZE=
```

---


## ğŸš€ 3. Running the Project

### Step 1 â€” Start the Backend (FastAPI)
```bash
uvicorn main:app --reload
```

### Step 2 â€” Start the Frontend (Streamlit)
```bash
streamlit run streamlit.py
```

---

## ğŸ“‚ 4. Project Structure

```
Documents/                    
src/
â”‚
â”œâ”€â”€ Agents/                    
â”‚   â”œâ”€â”€ LangGraphAgent.py       # LangGraph conversation flow agent
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ Config/                     # Configuration files
â”‚   â”œâ”€â”€ config.py               # Loads env variables and settings
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ Database/                   # Document storage
â”‚   â”œâ”€â”€ vectordb/                # Vector embeddings for retrieval
â”‚
â”œâ”€â”€ LLMs/                       # Large Language Model integrations
â”‚   â”œâ”€â”€ Embedding.py             # Generates embeddings from text
â”‚   â”œâ”€â”€ Gemini.py                # Google Gemini LLM wrapper
â”‚   â”œâ”€â”€ Prompts/                 # Prompt templates for queries
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ Routes/                     # API endpoints
â”‚   â””â”€â”€ ...                     # (Files for FastAPI routes)
â”‚
â”œâ”€â”€ main.py                     # FastAPI entrypoint
â”œâ”€â”€ streamlit.py                 # Streamlit chat UI
â”œâ”€â”€ requirements.txt             # Dependencies
â”œâ”€â”€ .env                         # Environment variables (ignored in Git)
â”œâ”€â”€ .env.example                 # Example .env template
â”œâ”€â”€ langgraph.png                # LangGraph diagram (generated)
â””â”€â”€ README.md                    # This file
```

---

## ğŸ§  5. How it Works


1. **Upload PDF** (via Streamlit sidebar) â†’ sent to `/data/upload` endpoint â†’ stored in `Database/datastore` and processed into vector embeddings in `Database/vectordb`.

2. **Ask a Question** in chat:
   - **RAG Mode** â†’ Sends query to `/chat/chat` â†’ Retrieves relevant chunks from vector DB â†’ Passes context to LLM.
   - **LangGraph Mode** â†’ Sends query to `/langgraph/chat_langgraph` â†’ Processes via LangGraphâ€™s state machine to manage conversation limits and structured responses.

3. **Response** is displayed in Streamlit chat.

---

## ğŸ“Š 6. Key Components


- **LangGraphAgent.py**
  - Defines a LangGraph workflow with nodes:
    - `check_counter` â†’ checks message limit
    - `call_llm` â†’ sends query to Gemini API
    - `end_conversation` â†’ stops when limit exceeded

- **config.py**
  - Central place for reading `.env` variables.

- **Embedding.py**
  - Generates embeddings from text for retrieval.

- **Gemini.py**
  - Wrapper for Google Gemini API.

- **Qdrant.py**
  - Integrates with Qdrant vector DB to create collections and store embeddings/texts.

- **Routes/**
  - API routes for:
    - Uploading documents, chunking, embedding, storage
    - Querying chat (RAG & LangGraph)

---


### Tips

- Keep your API keys private (never commit `.env` to GitHub).
- Start with **RAG mode** to understand basic retrieval before diving into LangGraph logic.
- Check `langgraph.png` to see a diagram of your LangGraph workflow.
- Experiment with prompt templates in `LLMs/Prompts`.
